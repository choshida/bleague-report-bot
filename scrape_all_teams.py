import requests
from bs4 import BeautifulSoup

# å¯¾å¿œãƒãƒ¼ãƒ ã®å®šç¾©ï¼ˆURLã¨ã‚»ãƒ¬ã‚¯ã‚¿ï¼‰
TEAMS = {
    "ç‰çƒã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚­ãƒ³ã‚°ã‚¹": {
        "url": "https://goldenkings.jp/news/",
        "base_url": "https://goldenkings.jp",
        "item_selector": ".list-item",
        "title_selector": ".list-title",
        "date_selector": ".list-date",
        "link_inside": "a"
    },
    "èŒ¨åŸãƒ­ãƒœãƒƒãƒ„": {
        "url": "https://www.ibarakirobots.win/news/",
        "base_url": "https://www.ibarakirobots.win",
        "item_selector": ".news-item",
        "title_selector": ".title",
        "date_selector": ".date",
        "link_inside": "a"
    },
    "ä¿¡å·ãƒ–ãƒ¬ã‚¤ãƒ–ã‚¦ã‚©ãƒªã‚¢ãƒ¼ã‚º": {
        "url": "https://www.b-warriors.net/news/",
        "base_url": "https://www.b-warriors.net",
        "item_selector": ".news__list-item",
        "title_selector": ".news__list-title",
        "date_selector": ".news__list-date",
        "link_inside": "a"
    }
}

def scrape_team(name, config):
    try:
        res = requests.get(config["url"], timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")
        items = soup.select(config["item_selector"])[:5]

        print(f"ğŸ€ {name}")
        for item in items:
            title_tag = item.select_one(config["title_selector"])
            date_tag = item.select_one(config["date_selector"])
            link_tag = item.select_one(config["link_inside"])

            if title_tag and date_tag and link_tag:
                print(f"{date_tag.get_text(strip=True)}ï½œ{title_tag.get_text(strip=True)}")
                print(f"â†’ {config['base_url']}{link_tag['href']}\n")
        print("-" * 40)
    except Exception as e:
        print(f"[ERROR] {name} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")

if __name__ == "__main__":
    for team, config in TEAMS.items():
        scrape_team(team, config)
